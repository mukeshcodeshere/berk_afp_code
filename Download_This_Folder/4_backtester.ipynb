{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKING CODE with backtest - individiual tickers - mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data for ticker: HRTX\n",
      "Adding data for ticker: REGN\n",
      "Adding data for ticker: UTHR\n",
      "Adding data for ticker: CLDX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [00:08<00:00, 44.74it/s]\n",
      "INFO:root:QuantStats report generated for strategy: buy_and_hold_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_buy_and_hold_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: close_vs_sma_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_close_vs_sma_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: mean_reversion_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_mean_reversion_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: prev_peak_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_prev_peak_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: random_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_random_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: prev_peak_nodrop_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_prev_peak_nodrop_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: close_vs_sma_nodrop_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_close_vs_sma_nodrop_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: mean_reversion_nodrop_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_mean_reversion_nodrop_strategy.html\n",
      "INFO:root:QuantStats report generated for strategy: anti_drop_strategy\n",
      "INFO:root:Report saved to: QuantStats_Reports/quantstats_report_anti_drop_strategy.html\n",
      "INFO:root:Strategy Evaluation Summary:\n",
      "INFO:root:                                mean_value  max_drawdown\n",
      "strategy                                                \n",
      "anti_drop_strategy                1.035206     86.071429\n",
      "buy_and_hold_strategy             1.528859     94.879314\n",
      "close_vs_sma_nodrop_strategy      0.959435     90.321717\n",
      "close_vs_sma_strategy             1.013512     85.087287\n",
      "mean_reversion_nodrop_strategy    0.942480     92.763685\n",
      "mean_reversion_strategy           1.099223     87.714866\n",
      "prev_peak_nodrop_strategy         1.128702     79.414032\n",
      "prev_peak_strategy                0.994017     89.460021\n",
      "random_strategy                   1.065016     92.356697\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "import backtrader as bt\n",
    "import quantstats as qs\n",
    "import os\n",
    "from bt_strategy import (\n",
    "    evaluate_strategies,\n",
    "    buy_and_hold_strategy,\n",
    "    close_vs_sma_strategy,\n",
    "    mean_reversion_strategy,\n",
    "    prev_peak_strategy,\n",
    "    random_strategy,\n",
    "    prev_peak_nodrop_strategy,\n",
    "    close_vs_sma_nodrop_strategy,\n",
    "    mean_reversion_nodrop_strategy,\n",
    "    anti_drop_strategy\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set Pandas option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Evaluate strategies with multiple trials and parallel processing\n",
    "n_trials = 10  # Number of trials per strategy per ticker\n",
    "n_jobs = -1     # Use all available CPU cores\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define your reporting folder (ensure this exists)\n",
    "REPORTS_FOLDER = \"QuantStats_Reports\"\n",
    "os.makedirs(REPORTS_FOLDER, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Constants\n",
    "DB_PATH = r\"/Users/mukeshwaranbaskaran/Documents/MFE Notes/Term 4/AFP/Code/Download_This_Folder/1_financial_data.db\"\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2023-12-31'\n",
    "\n",
    "# Function to load distinct tickers from the SQLite database\n",
    "def load_distinct_tickers_from_db():\n",
    "    \"\"\"Load distinct tickers from the database within the specified date range.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT ticker\n",
    "        FROM merged_data\n",
    "        WHERE date BETWEEN ? AND ?\n",
    "    \"\"\"\n",
    "    distinct_tickers = pd.read_sql(query, conn, params=(START_DATE, END_DATE))\n",
    "    conn.close()\n",
    "    return distinct_tickers\n",
    "\n",
    "# Load tickers and order alphabetically\n",
    "tickers = load_distinct_tickers_from_db()\n",
    "\n",
    "# Assuming the result is a DataFrame, extract the 'ticker' column\n",
    "tickers_list_full = tickers['ticker'].tolist()\n",
    "tickers_list_mini = ['REGN','UTHR','CLDX','XOMA','AXGN','HRTX','OCUP','CAPR']#,'OMER','IRWD','CRMD']\n",
    "\n",
    "# Function to load data from the SQLite database\n",
    "def load_data_from_db(tickers_list):\n",
    "    \"\"\"Load data from the database within the specified date range, excluding tickers with no data.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    # Convert tickers_list into a format suitable for the SQL IN clause (comma-separated string)\n",
    "    tickers_tuple = tuple(tickers_list)\n",
    "    \n",
    "    # Make sure tickers_tuple is not empty to prevent SQL errors\n",
    "    if not tickers_tuple:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no tickers are provided\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM merged_data\n",
    "        WHERE date BETWEEN ? AND ?\n",
    "        AND ticker IN ({})\n",
    "    \"\"\".format(','.join(['?'] * len(tickers_tuple)))  # Dynamically insert placeholders for each ticker\n",
    "\n",
    "    # Run the query with the tickers_list as parameters\n",
    "    params = (START_DATE, END_DATE) + tickers_tuple\n",
    "    merged_data = pd.read_sql(query, conn, params=params)\n",
    "    \n",
    "    conn.close()\n",
    "    return merged_data\n",
    "\n",
    "# Load and preprocess data\n",
    "merged_data = load_data_from_db(tickers_list_mini)\n",
    "merged_data['date'] = pd.to_datetime(merged_data['date'], errors='coerce')\n",
    "merged_data.sort_values('date', inplace=True)\n",
    "merged_data.set_index('date', inplace=True)\n",
    "\n",
    "equities_cols_needed = ['permno', 'cusip', 'bid', 'ask', 'vol', 'shrout', 'prc', 'mktcap', 'ticker']\n",
    "merged_data_equities = merged_data[equities_cols_needed]\n",
    "\n",
    "# Drop duplicate rows & reset index\n",
    "merged_data_equities_no_duplicates = merged_data_equities.drop_duplicates()\n",
    "merged_data_equities_no_duplicates_reset_index = merged_data_equities_no_duplicates.reset_index()\n",
    "\n",
    "# ERRORS WITH LESS THAN 800 rows of data per ticker\n",
    "def filter_tickers_with_min_rows(df, min_rows=800):\n",
    "    # Group by 'ticker' and count the rows for each ticker\n",
    "    ticker_counts = df.groupby('ticker').size()\n",
    "    \n",
    "    # Identify tickers with more than the minimum required rows\n",
    "    valid_tickers = ticker_counts[ticker_counts >= min_rows].index.tolist()\n",
    "    \n",
    "    # Filter the DataFrame to only include rows for these tickers\n",
    "    filtered_data_800 = df[df['ticker'].isin(valid_tickers)]\n",
    "    \n",
    "    #print(f\"Filtered DataFrame with only tickers that have at least {min_rows} rows.\")\n",
    "    \n",
    "    return filtered_data_800\n",
    "\n",
    "filtered_data_800 = filter_tickers_with_min_rows(merged_data_equities_no_duplicates_reset_index)\n",
    "\n",
    "# Convert to OHLC format for backtrader\n",
    "def convert_to_ohlc_format(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    grouped = df.groupby(['date', 'ticker'])\n",
    "    result = grouped.agg(\n",
    "        Open=('bid', 'first'),\n",
    "        High=('ask', 'max'),\n",
    "        Low=('bid', 'min'),\n",
    "        Close=('prc', 'last'),  # Use 'prc' for closing price here\n",
    "        Adj_Close=('prc', 'last'),\n",
    "        Volume=('vol', 'sum')\n",
    "    ).reset_index()\n",
    "    result.set_index('date', inplace=True)\n",
    "    result.rename(columns={'ticker': 'Ticker'}, inplace=True)\n",
    "    return result\n",
    "\n",
    "merged_equities_OHLC = convert_to_ohlc_format(filtered_data_800)\n",
    "\n",
    "# BACKTESTING \n",
    "\n",
    "# Initialize Cerebro engine\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "# Add data feeds for all tickers\n",
    "unique_tickers = merged_equities_OHLC['Ticker'].unique()\n",
    "\n",
    "for ticker in unique_tickers:\n",
    "    print(f\"Adding data for ticker: {ticker}\")\n",
    "    \n",
    "    # Filter data for the current ticker\n",
    "    ticker_data = merged_equities_OHLC[merged_equities_OHLC['Ticker'] == ticker]\n",
    "    ticker_data.index = pd.to_datetime(ticker_data.index)\n",
    "    ticker_data = ticker_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    # Define custom PandasData feed for backtrader\n",
    "    class PandasData(bt.feeds.PandasData):\n",
    "        params = (\n",
    "            ('datetime', None),\n",
    "            ('open', 'Open'),\n",
    "            ('high', 'High'),\n",
    "            ('low', 'Low'),\n",
    "            ('close', 'Close'),\n",
    "            ('volume', 'Volume'),\n",
    "            ('openinterest', None),\n",
    "        )\n",
    "\n",
    "    # Add this ticker's data feed to Cerebro\n",
    "    data_feed = PandasData(dataname=ticker_data)\n",
    "    cerebro.adddata(data_feed, name=ticker)\n",
    "\n",
    "# Define strategies to evaluate\n",
    "strategies = [\n",
    "    buy_and_hold_strategy,\n",
    "    close_vs_sma_strategy,\n",
    "    mean_reversion_strategy,\n",
    "    prev_peak_strategy,\n",
    "    random_strategy,\n",
    "    prev_peak_nodrop_strategy,\n",
    "    close_vs_sma_nodrop_strategy,\n",
    "    mean_reversion_nodrop_strategy,\n",
    "    anti_drop_strategy\n",
    "]\n",
    "\n",
    "# Prepare logs for each ticker's OHLC data\n",
    "logs = {ticker: merged_equities_OHLC[merged_equities_OHLC['Ticker'] == ticker] for ticker in unique_tickers}\n",
    "\n",
    "results_df = evaluate_strategies(strategies, logs, n_trials, n_jobs)\n",
    "\n",
    "# Save results to a CSV file (optional)\n",
    "results_df.to_csv(f\"{REPORTS_FOLDER}/strategy_evaluation_results.csv\", index=False)\n",
    "\n",
    "# Function to generate QuantStats reports\n",
    "def generate_quantstats_report(logs, strategies):\n",
    "    \"\"\"Generate and save one QuantStats report per strategy.\"\"\"\n",
    "    if not logs:\n",
    "        logging.warning(\"No logs available to generate reports.\")\n",
    "        return\n",
    "\n",
    "    for strategy in strategies:\n",
    "        try:\n",
    "            combined_data = pd.DataFrame()  # To store combined data for each strategy\n",
    "            for ticker in logs.keys():  # Use only the tickers in 'logs'\n",
    "                ticker_data = logs[ticker]\n",
    "                \n",
    "                # Ensure the ticker data is in the format QuantStats expects\n",
    "                # 'Close' as the column representing the stock's price (closing price)\n",
    "                combined_data[ticker] = ticker_data['Close']\n",
    "\n",
    "            # Create a QuantStats report for the combined data of this strategy\n",
    "            qs.extend_pandas()  # Ensure QuantStats can extend Pandas functionalities\n",
    "            report_filename = f'quantstats_report_{strategy.__name__}.html'\n",
    "            report_path = os.path.join(REPORTS_FOLDER, report_filename)\n",
    "            qs.reports.html(combined_data, output=report_path, title=f'QuantStats Report for {strategy.__name__}')\n",
    "            logging.info(f\"QuantStats report generated for strategy: {strategy.__name__}\")\n",
    "            logging.info(f\"Report saved to: {report_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating QuantStats report for strategy {strategy.__name__}: {e}\")\n",
    "\n",
    "# Generate the QuantStats reports for each strategy\n",
    "generate_quantstats_report(logs, strategies)\n",
    "\n",
    "# EVALUATION - Strategy performance stats\n",
    "# Grouping results by strategy name to calculate mean value and max drawdown\n",
    "strategy_summary = results_df.groupby('strategy').agg(\n",
    "    mean_value=('value', 'mean'),\n",
    "    max_drawdown=('dropdown', 'max')\n",
    ")\n",
    "\n",
    "# Print the evaluation summary\n",
    "logging.info(\"Strategy Evaluation Summary:\")\n",
    "logging.info(strategy_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If mean_value = 1.1293, it means the strategy has generated a 12.93% gain. ; max_drawdown is percentage units"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
